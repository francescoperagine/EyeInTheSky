{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "\n",
    "%pip install loguru==0.7.3 python-dotenv==1.0.1 PyYAML==6.0.2 torch==2.6.0 torchvision==0.21.0 tqdm==4.67.1 typer==0.15.1 matplotlib==3.10.0 pyarrow==18.1.0 setuptools==75.1.0 protobuf==4.25.3 ultralytics==8.3.107 ray==2.43.0 albumentations==2.0.5 shortuuid==1.0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from ultralytics import YOLO, settings\n",
    "from ultralytics.data.dataset import YOLODataset\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from ultralytics.utils import colorstr, LOGGER, SettingsManager\n",
    "from ultralytics.utils.torch_utils import one_cycle\n",
    "import gc\n",
    "import glob\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shortuuid\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import wandb\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def load_config(config_file: str) -> dict:\n",
    "    \"\"\"Load and return configuration from YAML file.\"\"\"\n",
    "    with open(config_file, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def _get_wandb_key_colab() -> str:\n",
    "    try:\n",
    "        from google.colab import userdata # type: ignore\n",
    "\n",
    "        if userdata.get(\"WANDB_API_KEY\") is not None:\n",
    "            return userdata.get(\"WANDB_API_KEY\")\n",
    "        else:\n",
    "            raise ValueError(\"No WANDB key found\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def _get_wandb_env(path: Path) -> str:\n",
    "    try:\n",
    "        from dotenv import dotenv_values # type: ignore\n",
    "\n",
    "        \"\"\"Get W&B API key from Colab userdata or environment variable\"\"\"\n",
    "\n",
    "        path = Path(path)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Could not find .env file at {path}\")\n",
    "\n",
    "        print(f\"Loading secrets from {path}\")\n",
    "\n",
    "        secrets = dotenv_values(path)\n",
    "        print(f\"Found keys: {list(secrets.keys())}\")\n",
    "\n",
    "        if \"WANDB_API_KEY\" not in secrets:\n",
    "            raise KeyError(f\"WANDB_API_KEY not found in {path}. Available keys: {list(secrets.keys())}\")\n",
    "\n",
    "        return secrets['WANDB_API_KEY']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_wandb_key(path: Path = \"../.env\") -> str:\n",
    "    return _get_wandb_key_colab() if _get_wandb_key_colab() is not None else _get_wandb_env(path)\n",
    "\n",
    "def clear_cache():\n",
    "    # Clear CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Clear Python garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "def get_device() -> str:\n",
    "    try:\n",
    "        return 0 if torch.cuda.is_available() else \"cpu\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting device: {e}\")\n",
    "\n",
    "def remove_models():\n",
    "    pt_files = glob.glob(\"*.pt\")\n",
    "    print(\"Files to be removed:\", pt_files)\n",
    "\n",
    "    for file in pt_files:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path\n",
    "\n",
    "ROOT_PATH = Path.cwd().parents[0]\n",
    "DATASET_PATH = os.path.join(ROOT_PATH, \"data\", \"raw\") # Should also change the path in visdrone.yaml to point to the new location\n",
    "WEIGHTS_PATH = os.path.join(ROOT_PATH, \"models\")\n",
    "RUNS_PATH = os.path.join(ROOT_PATH, \"runs\")\n",
    "WANDB_REPORT_PATH = os.path.join(ROOT_PATH, \"reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = SettingsManager()\n",
    "settings.update(\n",
    "    # runs_dir=RUNS_PATH, \n",
    "    # weights_dir=WEIGHTS_PATH,\n",
    "    # datasets_dir=DATASET_PATH,\n",
    "    wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "config_data = \"\"\"\n",
    "wandb: # Mandatory to use wandb to track the metrics\n",
    "  project: \"EyeInTheSky_merged\"\n",
    "  group: \"distillation\"\n",
    "  dir: \"reports\"\n",
    "distillation:\n",
    "  use_cyclical_lr: False\n",
    "  feature_layers: [11, 14, 17, 20] # Layers to extract features from\n",
    "  visualize_feature_plot: False\n",
    "  feature_plot_interval: 20 # Interval for plotting features\n",
    "  temperature: 2.0 # Temperature for distillation\n",
    "  alpha: 0.5 # Weight for the distillation loss\n",
    "  max_lr: 0.01 # Maximum learning rate for the cyclical learning rate\n",
    "  cycle_size: 20 # Number of epochs for each cycle\n",
    "  group_scalers: {0: 1.0, 1: 1.0, 2: 1.0}\n",
    "  teacher_model_path: \"francescoperagine-universit-degli-studi-di-bari-aldo-moro/EyeInTheSky_merged/run_sdrn2wmo_model:v0\" # Path to the teacher model. Do not leave it in the current directory as it will be removed.\n",
    "train:\n",
    "  project: \"EyeInTheSky\"\n",
    "  data: \"VisDrone.yaml\"\n",
    "  model: \"yolo12n.pt\" # Model with weights. To train it from scratch, use \"yolo12n.yaml with pretrained: False\"\n",
    "  pretrained: True # Read above\n",
    "  patience: 5\n",
    "  task: detect\n",
    "  epochs: 150\n",
    "  weight_decay: 0.0\n",
    "  lr0: 0.001\n",
    "  lrf: 0.001\n",
    "  nbs: 64\n",
    "  seed: 42\n",
    "  plots: True\n",
    "  exist_ok: False\n",
    "  save: True\n",
    "  save_period: 5\n",
    "  val: True\n",
    "  warmup_epochs: 5\n",
    "  visualize: True\n",
    "  show: True\n",
    "  single_cls: False\n",
    "  rect: False\n",
    "  resume: False\n",
    "  fraction: 1.0\n",
    "  freeze: None\n",
    "  cache: False\n",
    "  verbose: False\n",
    "  amp: True\n",
    "  save_crop: True\n",
    "  save_conf: True\n",
    "  save_txt: True\n",
    "  save_json: True\n",
    "val:\n",
    "  project: \"EyeInTheSky\"\n",
    "  task: detect\n",
    "  data: \"VisDrone.yaml\"\n",
    "  half: True\n",
    "  conf: 0.25\n",
    "  iou: 0.6\n",
    "  split: \"test\"\n",
    "  rect: True\n",
    "  plots: True\n",
    "  visualize: True\n",
    "  verbose: False\n",
    "  save_crop: True\n",
    "  save_conf: True\n",
    "  save_txt: True\n",
    "  save_json: True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "# config_path = root / \"config\" / \"config.yaml\"\n",
    "# config = load_config(config_path)\n",
    "\n",
    "config = yaml.safe_load(config_data)\n",
    "\n",
    "config[\"wandb\"].update({\n",
    "    \"dir\": WANDB_REPORT_PATH,\n",
    "})\n",
    "\n",
    "config[\"train\"].update({\n",
    "    \"device\" : get_device(),\n",
    "    # \"save_dir\": RUNS_PATH,\n",
    "})\n",
    "\n",
    "config[\"val\"].update({\n",
    "    \"device\" : get_device(),\n",
    "    # \"save_dir\": RUNS_PATH,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset, Trainer, Validator\n",
    "\n",
    "class VisDroneDataset(YOLODataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for VisDrone that merges pedestrian (0) and people (1) classes.\n",
    "    \n",
    "    This dataset handler performs class remapping at the earliest stage of the pipeline\n",
    "    by combining pedestrian and people into a single 'persona' class and shifting all \n",
    "    other class indices down by one. The merged class mapping is stored as a class \n",
    "    attribute for access during training and validation.\n",
    "    \n",
    "    The remapping happens in the get_labels() method which modifies the label tensors\n",
    "    directly, ensuring all downstream processing uses the merged classes.\n",
    "    \n",
    "    Class attributes:\n",
    "        merged_names (dict): New class mapping after merging pedestrian and people classes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the merged names as a class attribute to be accessible from the trainer\n",
    "    merged_names = {\n",
    "        0: 'persona',\n",
    "        1: 'bicicletta',\n",
    "        2: 'auto',\n",
    "        3: 'furgone',\n",
    "        4: 'camion',\n",
    "        5: 'triciclo',\n",
    "        6: 'triciclo-tendato',\n",
    "        7: 'autobus',\n",
    "        8: 'motociclo'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Initialize parent class with modified kwargs\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Log class mapping\n",
    "        LOGGER.info(f\"{colorstr('VisDroneDataset:')} Using merged classes: {self.merged_names}\")\n",
    "    \n",
    "    def get_labels(self):\n",
    "        \"\"\"\n",
    "        Load and process labels with class remapping.\n",
    "        \"\"\"\n",
    "        # Get labels from parent method\n",
    "        labels = super().get_labels()\n",
    "        \n",
    "        # Process statistics\n",
    "        people_count = 0\n",
    "        shifted_count = 0\n",
    "        \n",
    "        # Process labels to merge classes\n",
    "        for i in range(len(labels)):\n",
    "            cls = labels[i]['cls']\n",
    "            \n",
    "            if len(cls) > 0:\n",
    "                # Count 'people' instances\n",
    "                people_mask = cls == 1\n",
    "                people_count += np.sum(people_mask)\n",
    "                \n",
    "                # Merge class 1 (people) into class 0 (pedestrian -> person)\n",
    "                cls[people_mask] = 0\n",
    "                \n",
    "                # Shift classes > 1 down by 1\n",
    "                gt1_mask = cls > 1\n",
    "                shifted_count += np.sum(gt1_mask)\n",
    "                cls[gt1_mask] -= 1\n",
    "                \n",
    "                # Store modified labels\n",
    "                labels[i]['cls'] = cls\n",
    "        \n",
    "        # Now set correct class count and names for training\n",
    "        if hasattr(self, 'data'):\n",
    "            # Update names and class count\n",
    "            self.data['names'] = self.merged_names\n",
    "            self.data['nc'] = len(self.merged_names)\n",
    "        \n",
    "        # Log statistics\n",
    "        person_count = sum(np.sum(label['cls'] == 0) for label in labels)\n",
    "        LOGGER.info(f\"\\n{colorstr('VisDroneDataset:')} Remapped {people_count} 'people' instances to {self.merged_names[0]}\")\n",
    "        LOGGER.info(f\"{colorstr('VisDroneDataset:')} Total 'persona' instances after merge: {person_count}\")\n",
    "        LOGGER.info(f\"{colorstr('VisDroneDataset:')} Shifted {shifted_count} instances of other classes\")\n",
    "        \n",
    "        return labels\n",
    "\n",
    "class MergedClassDetectionTrainer(DetectionTrainer):\n",
    "    \"\"\"\n",
    "    Custom YOLO trainer that uses the VisDroneDataset with merged classes.\n",
    "    \n",
    "    Extends the standard DetectionTrainer to work with the merged-class dataset.\n",
    "    The key modifications are in build_dataset() to use VisDroneDataset instead of\n",
    "    the default, and in set_model_attributes() to properly update the model's class\n",
    "    names and count to match the merged dataset.\n",
    "    \n",
    "    This ensures that all aspects of training - from data loading to loss calculation -\n",
    "    work consistently with the merged class structure.\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_dataset(self, img_path, mode=\"train\", batch=None):\n",
    "        \"\"\"Build custom VisDroneDataset.\"\"\"\n",
    "        return VisDroneDataset(\n",
    "            img_path=img_path,\n",
    "            imgsz=self.args.imgsz,\n",
    "            batch_size=batch or self.batch_size,\n",
    "            augment=mode == \"train\",\n",
    "            hyp=self.args,\n",
    "            rect=self.args.rect if mode == \"train\" else True,\n",
    "            cache=self.args.cache or None,\n",
    "            single_cls=self.args.single_cls,\n",
    "            stride=self.stride,\n",
    "            pad=0.0 if mode == \"train\" else 0.5,\n",
    "            prefix=colorstr(f\"{mode}: \"),\n",
    "            task=self.args.task,\n",
    "            classes=None,\n",
    "            data=self.data,\n",
    "            fraction=self.args.fraction if mode == \"train\" else 1.0,\n",
    "        )\n",
    "    \n",
    "    def get_model(self, cfg=None, weights=None, verbose=True):\n",
    "        \"\"\"Create and return a DetectionModel.\"\"\"\n",
    "        \n",
    "        model = DetectionModel(\n",
    "            cfg=cfg, \n",
    "            nc=self.data[\"nc\"],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        model.args = self.args\n",
    "        \n",
    "        if weights:\n",
    "            LOGGER.info(f\"Loading weights into model\")\n",
    "            model.load(weights)\n",
    "            \n",
    "        return model    \n",
    "    \n",
    "    def set_model_attributes(self):\n",
    "        \"\"\"Update model attributes for merged classes.\"\"\"\n",
    "        # First call parent method to set standard attributes\n",
    "        super().set_model_attributes()\n",
    "        \n",
    "        # Then update model with the merged class names\n",
    "        if hasattr(self.model, 'names'):\n",
    "            # Use the merged names directly from the dataset class\n",
    "            self.model.names = VisDroneDataset.merged_names\n",
    "            self.model.nc = len(VisDroneDataset.merged_names)\n",
    "            \n",
    "            # Also update data dictionary\n",
    "            if hasattr(self, 'data'):\n",
    "                self.data['names'] = VisDroneDataset.merged_names\n",
    "                self.data['nc'] = len(VisDroneDataset.merged_names)\n",
    "\n",
    "class MergedClassDetectionValidator(DetectionValidator):\n",
    "    \"\"\"\n",
    "    Custom validator for evaluating models trained on merged VisDrone classes.\n",
    "    \n",
    "    Works in tandem with MergedClassDetectionTrainer to ensure that validation\n",
    "    uses the same class merging as training. The build_dataset() method creates\n",
    "    VisDroneDataset instances for validation, and set_model_attributes() updates\n",
    "    the model's class configuration to match the merged dataset.\n",
    "    \n",
    "    This allows for consistent metrics calculation across training and evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_dataset(self, img_path, mode=\"val\", batch=None):\n",
    "        \"\"\"Build custom VisDroneDataset for validation.\"\"\"\n",
    "        return VisDroneDataset(\n",
    "            img_path=img_path,\n",
    "            imgsz=self.args.imgsz,\n",
    "            batch_size=batch or self.args.batch,\n",
    "            augment=False,\n",
    "            hyp=self.args,\n",
    "            rect=self.args.rect,\n",
    "            cache=None,\n",
    "            single_cls=self.args.single_cls,\n",
    "            stride=self.stride,\n",
    "            pad=0.5,\n",
    "            prefix=colorstr(f\"{mode}: \"),\n",
    "            task=self.args.task,\n",
    "            classes=None,\n",
    "            data=self.data,\n",
    "        )\n",
    "       \n",
    "    def set_model_attributes(self):\n",
    "        \"\"\"Update model attributes for merged classes if using a PyTorch model.\"\"\"\n",
    "        super().set_model_attributes()\n",
    "        \n",
    "        # Then update model with the merged class names\n",
    "        if hasattr(self.model, 'names'):\n",
    "            # Use the merged names directly from the dataset class\n",
    "            self.model.names = VisDroneDataset.merged_names\n",
    "            self.model.nc = len(VisDroneDataset.merged_names)\n",
    "            \n",
    "            # Also update data dictionary\n",
    "            if hasattr(self, 'data'):\n",
    "                self.data['names'] = VisDroneDataset.merged_names\n",
    "                self.data['nc'] = len(VisDroneDataset.merged_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureAdaptation\n",
    "\n",
    "class FeatureAdaptation(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom neural network layer that adapts student features to match teacher dimensions.\n",
    "    \n",
    "    This module performs feature transformation between different network architectures,\n",
    "    enabling more effective knowledge distillation. It includes:\n",
    "    \n",
    "    1. Channel attention gating to emphasize important features\n",
    "    2. Spatial context modules (with varying complexity based on layer importance)\n",
    "    3. Channel dimension adaptation\n",
    "    \n",
    "    The adaptation process allows for comparing features from different network sizes\n",
    "    (e.g., YOLOv12n student vs. YOLOv12x teacher) by transforming the student's\n",
    "    feature space to align with the teacher's.\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): Number of input channels (from student model)\n",
    "        out_channels (int): Number of output channels (to match teacher model)\n",
    "        layer_idx (int, optional): Layer index to determine adaptation complexity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, layer_idx=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Determine if this layer should use spatial context\n",
    "        use_spatial = layer_idx in [8, 11, 14, 17, 20] \n",
    "        \n",
    "        # Add gating mechanism for all layers\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # Global pooling to get channel-wise statistics\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),    # ReLU for non-linearity\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()              # Output in range [0,1] to act as gates\n",
    "        )\n",
    "        \n",
    "        if use_spatial:\n",
    "            # For the most critical layers, use full depthwise\n",
    "            self.spatial = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=in_channels)\n",
    "           \n",
    "        else:\n",
    "            # For moderately important layers, use simpler spatial context\n",
    "            self.spatial = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=in_channels//4)\n",
    "            \n",
    "        # Regular channel adapter\n",
    "        self.adapter = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "        # Initialize with Kaiming normalization\n",
    "        nn.init.kaiming_normal_(self.adapter.weight)\n",
    "\n",
    "        # Initialize with small weights to maintain stability\n",
    "        nn.init.xavier_normal_(self.spatial.weight, gain=0.1)\n",
    "            \n",
    "        # Initialize gate with small weights to start with mild gating\n",
    "        for m in self.gate.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_normal_(m.weight, gain=0.1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Compute importance gates\n",
    "        importance = self.gate(x)\n",
    "        \n",
    "        # Applies attention weights to features to emphatize the most informative features\n",
    "        gated_features = x * importance\n",
    "        \n",
    "        # Apply spatial context if available\n",
    "        if self.spatial is not None:\n",
    "            # Apply spatial context with residual connection (on gated features)\n",
    "            gated_features = self.spatial(gated_features) + gated_features\n",
    "            \n",
    "        # Apply channel adaptation\n",
    "        return self.adapter(gated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecayingCyclicalLR scheduler\n",
    "\n",
    "class DecayingCyclicalLRSchedulerCallback:\n",
    "    \"\"\"\n",
    "    Callback that sets up the decaying cyclical learning rate scheduler.\n",
    "    \n",
    "    This callback integrates a custom learning rate scheduler into the training process\n",
    "    by attaching it to the trainer during the pretrain routine. It forwards configuration\n",
    "    parameters from the distillation config to the scheduler itself.\n",
    "    \n",
    "    Args:\n",
    "        **kwargs: Configuration parameters from config[\"distillation\"], including:\n",
    "            max_lr (float): Maximum learning rate peak\n",
    "            cycle_size (int): Number of epochs per cycle\n",
    "            group_scalers (dict): Per-parameter group learning rate multipliers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def set_scheduler(self, trainer):\n",
    "        trainer.scheduler = DecayingCyclicalLR(\n",
    "            trainer=trainer, \n",
    "            **self.kwargs\n",
    "        )\n",
    "\n",
    "class DecayingCyclicalLR(LRScheduler):\n",
    "    \"\"\"\n",
    "    Learning rate scheduler that combines cyclical patterns with gradual decay.\n",
    "    \n",
    "    Creates a wave-like learning rate pattern that oscillates between min_lr and max_lr\n",
    "    while gradually decreasing the overall magnitude over time. Features include:\n",
    "    \n",
    "    1. Initial warmup phase with linear lr increase\n",
    "    2. Cyclical pattern using cosine interpolation\n",
    "    3. Gradual decay of cycle amplitude over training\n",
    "    4. Support for different lr multipliers per parameter group\n",
    "    \n",
    "    Args:\n",
    "        trainer: The trainer instance to access optimizer and training parameters\n",
    "        **kwargs: Configuration parameters from config[\"distillation\"], including:\n",
    "            max_lr (float): Peak learning rate multiplier\n",
    "            cycle_size (int): Number of epochs in each lr cycle\n",
    "            group_scalers (dict): Parameter group-specific lr multipliers\n",
    "    \n",
    "    The scheduler integrates the trainer's built-in parameters like epochs, lrf (final lr factor),\n",
    "    and warmup_epochs with the distillation-specific configuration.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 trainer, \n",
    "                 **kwargs\n",
    "            ):\n",
    "        self.optimizer = trainer.optimizer\n",
    "        self.min_lr = trainer.args.lr0\n",
    "        self.max_lr = trainer.args.lr0 * 10 if kwargs.get(\"max_lr\") is None else kwargs.get(\"max_lr\")\n",
    "        self.lrf = trainer.args.lrf\n",
    "        self.cycle_size = kwargs.get(\"cycle_size\", 20)\n",
    "        self.warmup_epochs = trainer.args.warmup_epochs if hasattr(trainer.args, 'warmup_epochs') else 0\n",
    "        self.warmup_start_lr = trainer.args.warmup_start_lr if hasattr(trainer.args, 'warmup_start_lr') else self.min_lr * 0.1\n",
    "        self.epochs = trainer.args.epochs\n",
    "\n",
    "        self.group_scalers = kwargs.get(\"group_scalers\") if kwargs.get(\"group_scalers\") is not None else {0: 1.0, 1: 1.0, 2: 1.0}\n",
    "\n",
    "        # Debug logging\n",
    "        LOGGER.info(f\"DecayingCyclicalLR: Min lr: {self.min_lr}, Max lr: {self.max_lr}, Cycle size: {self.cycle_size}, cycle size: {self.cycle_size}, lrf: {self.lrf}, group_scalers: {self.group_scalers}, warmup_epochs: {self.warmup_epochs}, warmup_start_lr: {self.warmup_start_lr}, epochs: {self.epochs}\")\n",
    "\n",
    "        super().__init__(self.optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        # During warmup: gradually increase from warmup_start_lr to min_lr over warmup_steps\n",
    "        if self.last_epoch < self.warmup_epochs:\n",
    "            warmup_factor = self.last_epoch / max(1, self.warmup_epochs)\n",
    "            base_lr = self.warmup_start_lr + (self.min_lr - self.warmup_start_lr) * warmup_factor\n",
    "            return [base_lr * self.group_scalers.get(i, 1.0) for i in range(len(self.optimizer.param_groups))]\n",
    "\n",
    "        # After warmup: adjust using cyclical pattern with decay\n",
    "        post_warmup_epoch = self.last_epoch - self.warmup_epochs\n",
    "        remaining_epochs = self.epochs - self.warmup_epochs\n",
    "\n",
    "        # Across-cycles decay (outer schedule)\n",
    "        progress = post_warmup_epoch / max(1, remaining_epochs)\n",
    "        progress = min(1.0, progress)  # cap at 1.0\n",
    "\n",
    "        # decay_factor = self.lr_final_factor ** progress # Exponential decay\n",
    "        # decay_factor = (1 - progress) ** 2 + self.lr_final_factor * progress # Quadratic decay\n",
    "        # decay_factor = self.lr_final_factor + (1 - self.lr_final_factor) * 0.5 * (1 + math.cos(math.pi * progress)) # Cosine decay\n",
    "        decay_factor = 1.0 - (1.0 - self.lrf) * progress  # Linear decay\n",
    "\n",
    "        current_min_lr = self.min_lr * decay_factor\n",
    "        current_max_lr = self.max_lr * decay_factor\n",
    "\n",
    "        cycle_position = post_warmup_epoch % self.cycle_size\n",
    "\n",
    "        # Cosine interpolation - adjusted to ensure proper cycle behavior\n",
    "        # Produces a value that starts at 0, peaks at 1 at half cycle, and returns to 0\n",
    "        normalized = cycle_position / self.cycle_size  # 0 to 1 over the cycle\n",
    "        # Modified cosine formula: 0.5 * (1 - cos(2π * normalized))\n",
    "        # At normalized=0: 0.5 * (1 - cos(0)) = 0.5 * (1 - 1) = 0\n",
    "        # At normalized=0.5: 0.5 * (1 - cos(π)) = 0.5 * (1 - (-1)) = 1\n",
    "        # At normalized=1: 0.5 * (1 - cos(2π)) = 0.5 * (1 - 1) = 0\n",
    "        factor = 0.5 * (1 - math.cos(2 * math.pi * normalized))\n",
    "        \n",
    "        # Calculate learning rate\n",
    "        base_lr = current_min_lr + (current_max_lr - current_min_lr) * factor\n",
    "\n",
    "        # Apply group-specific scaling\n",
    "        groups_lrs = [np.float64(base_lr * self.group_scalers.get(i, 1.0)) for i in range(len(self.optimizer.param_groups))]\n",
    "        return groups_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distillation Callback\n",
    "\n",
    "class DistillationCallback:\n",
    "    \"\"\"\n",
    "    Core callback that implements the knowledge distillation process.\n",
    "    \n",
    "    This callback manages the entire feature-based distillation mechanism by:\n",
    "    \n",
    "    1. Capturing intermediate features from both teacher and student models\n",
    "    2. Creating and managing feature adaptation layers to align dimensions\n",
    "    3. Computing cosine similarity losses between adapted features\n",
    "    4. Balancing detection loss with feature distillation loss\n",
    "    5. Learning optimal layer importance weights and loss component weights\n",
    "    \n",
    "    The callback hooks into multiple phases of training:\n",
    "    - on_train_start: Initializes parameters and adds them to the optimizer\n",
    "    - on_train_epoch_start: Sets up feature extraction hooks and custom loss function\n",
    "    - on_fit_epoch_end: Logs metrics and visualizations to W&B\n",
    "    \n",
    "    Args:\n",
    "        teacher_model: Pretrained YOLO model to use as knowledge source\n",
    "        temperature (float): Controls softness of weight distribution (from config)\n",
    "        alpha (float): Balance between detection and distillation loss (from config)\n",
    "        feature_layers (list): Layer indices to extract features from (from config)\n",
    "        layer_channels (dict): Pre-computed channel dimensions for each layer\n",
    "    \n",
    "    The callback dynamically learns two sets of weights during training:\n",
    "    - layer_weights: Importance of each feature layer in the distillation loss\n",
    "    - component_weights: Automatic balancing of box/class/DFL loss components\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "            teacher_model, \n",
    "            temperature = 2.0, \n",
    "            alpha = 0.5, \n",
    "            feature_layers = [11, 14, 17, 20], \n",
    "            layer_channels = {}\n",
    "        ):\n",
    "\n",
    "        self.teacher_model = teacher_model\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.feature_layers = feature_layers\n",
    "        self.layer_channels = layer_channels\n",
    "        self.current_features = {}\n",
    "        self.teacher_hooks = {}\n",
    "        self.student_hooks = {}\n",
    "        self.adapters = {}\n",
    "        self.layer_weight_values = {layer_idx: 0.0 for layer_idx in self.feature_layers}\n",
    "        self.cosine_losses = []\n",
    "        self.detection_losses = []\n",
    "        self.distillation_losses = []\n",
    "        self.layer_weights = None\n",
    "        self.component_weights = None\n",
    "        self.component_weight_history = {'box': [], 'cls': [], 'dfl': []}\n",
    "        self.initialized = False\n",
    "\n",
    "    def init_parameters(self, trainer):\n",
    "        \"\"\"Initialize parameters and register them with optimizer once\"\"\"\n",
    "        if self.initialized:\n",
    "            return\n",
    "            \n",
    "        # Move teacher to student's device/dtype\n",
    "        device = next(self.teacher_model.parameters()).device\n",
    "        dtype = next(self.teacher_model.parameters()).dtype\n",
    "        self.teacher_model = self.teacher_model.to(device=device, dtype=dtype)\n",
    "        \n",
    "        # Initialize component weights\n",
    "        self.component_weights = nn.Parameter(torch.zeros(3, device=device))\n",
    "        self._add_optimizer_param_group(\n",
    "            trainer=trainer,\n",
    "            params=[self.component_weights],\n",
    "            name='loss_component_weights',\n",
    "            weight_decay_multiplier=0.2\n",
    "        )\n",
    "            \n",
    "        # Initialize layer weights\n",
    "        equal_weight = 1.0 / len(self.feature_layers)\n",
    "        weights_tensor = torch.tensor([equal_weight for _ in self.feature_layers], device=device)\n",
    "        self.layer_weights = nn.Parameter(weights_tensor, requires_grad=True)\n",
    "        self._add_optimizer_param_group(\n",
    "            trainer=trainer,\n",
    "            params=[self.layer_weights],\n",
    "            name='layer_weight_params',\n",
    "            weight_decay_multiplier=1.0\n",
    "        )\n",
    "        \n",
    "        # Create feature adapters\n",
    "        for layer_idx in self.feature_layers:\n",
    "            adapter_key = f'adapter_{layer_idx}'\n",
    "            \n",
    "            # Get channel dimensions from pre-computed values\n",
    "            if layer_idx in self.layer_channels:\n",
    "                student_channels = self.layer_channels[layer_idx]['student']\n",
    "                teacher_channels = self.layer_channels[layer_idx]['teacher']\n",
    "                \n",
    "                # Create feature adaptation layer with normalization\n",
    "                self.adapters[adapter_key] = FeatureAdaptation(student_channels, teacher_channels, layer_idx=layer_idx).to(device)\n",
    "                \n",
    "                # Add adapter parameters to optimizer with stronger regularization\n",
    "                self._add_optimizer_param_group(\n",
    "                    trainer=trainer,\n",
    "                    params=list(self.adapters[adapter_key].parameters()),\n",
    "                    name=f'adapter_params_{layer_idx}',\n",
    "                    weight_decay_multiplier=5.0\n",
    "                )\n",
    "            else:\n",
    "                LOGGER.warning(f\"Missing channel dimensions for layer {layer_idx}\")\n",
    "                \n",
    "        self.initialized = True\n",
    "        \n",
    "        # Set original criterion if not already done\n",
    "        if not hasattr(trainer.model, \"original_criterion\"):\n",
    "            trainer.model.original_criterion = trainer.model.init_criterion()\n",
    "    \n",
    "    def setup_criterion(self, trainer):\n",
    "        \"\"\"Register hooks for feature extraction\"\"\"\n",
    "        # Clear features dictionary\n",
    "        self.current_features = {}\n",
    "\n",
    "        def get_features(name, layer_idx):\n",
    "            def hook(module, input, output):\n",
    "                if name not in self.current_features:\n",
    "                    self.current_features[name] = {}\n",
    "                self.current_features[name][layer_idx] = output.detach()\n",
    "            return hook\n",
    "       \n",
    "        # Register hooks for both models at each feature layer\n",
    "        for layer_idx in self.feature_layers:\n",
    "            self.teacher_hooks[layer_idx] = self.teacher_model.model.model[layer_idx].register_forward_hook(\n",
    "                get_features('teacher', layer_idx)\n",
    "            )\n",
    "            self.student_hooks[layer_idx] = trainer.model.model[layer_idx].register_forward_hook(\n",
    "                get_features('student', layer_idx)\n",
    "            )\n",
    "        \n",
    "        # Define distillation criterion\n",
    "        def distillation_criterion(preds, batch):\n",
    "\n",
    "            # Get original loss\n",
    "            original_loss, loss_items = trainer.model.original_criterion(preds, batch)\n",
    "\n",
    "            # Apply uncertainty weighting (Kendall et al. 2018)\n",
    "            # Converting parameters to precisions using exponential - ensures positive weights\n",
    "            precision = torch.exp(-self.component_weights)\n",
    "\n",
    "            # Weight losses - dividing by precision penalizes high uncertainty components\n",
    "            weighted_loss = original_loss * precision + 0.5 * self.component_weights  # The 0.5 * log_var term is from the math derivation\n",
    "            weighted_detection_loss = weighted_loss.sum()\n",
    "\n",
    "            # Run teacher forward pass to capture features\n",
    "            with torch.no_grad():\n",
    "                self.teacher_model.eval()\n",
    "                teacher_input = batch[\"img\"].float()\n",
    "                _ = self.teacher_model.model(teacher_input)\n",
    "            \n",
    "            # Calculate cosine loss for each layer and combine\n",
    "            layer_losses = []\n",
    "            \n",
    "            for i, layer_idx in enumerate(self.feature_layers):\n",
    "                if ('teacher' in self.current_features and \n",
    "                    'student' in self.current_features and\n",
    "                    layer_idx in self.current_features['teacher'] and\n",
    "                    layer_idx in self.current_features['student']):\n",
    "                    \n",
    "                    t_feat = self.current_features['teacher'][layer_idx]\n",
    "                    s_feat = self.current_features['student'][layer_idx]\n",
    "                    \n",
    "                    # Apply adaptation to student features\n",
    "                    adapter_key = f'adapter_{layer_idx}'\n",
    "                    if adapter_key in self.adapters:\n",
    "                        s_feat_adapted = self.adapters[adapter_key](s_feat)\n",
    "                        \n",
    "                        # Normalize features\n",
    "                        t_feat = F.normalize(t_feat.flatten(1), p=2, dim=1)\n",
    "                        s_feat_adapted = F.normalize(s_feat_adapted.flatten(1), p=2, dim=1)\n",
    "                        \n",
    "                        # Cosine similarity loss for this layer\n",
    "                        layer_cosine_loss = 1 - F.cosine_similarity(s_feat_adapted, t_feat, dim=1).mean()\n",
    "                        layer_losses.append(layer_cosine_loss)\n",
    "\n",
    "            # Apply softmax to weights with minimum weight guarantee\n",
    "            alpha = 0.2  # This is your minimum weight parameter (not the same as distillation alpha)\n",
    "            uniform_weights = torch.ones_like(self.layer_weights) / len(self.layer_weights)\n",
    "            normalized_weights = (1 - alpha) * F.softmax(self.layer_weights / self.temperature, dim=0) + alpha * uniform_weights\n",
    "            # normalized_weights = F.softmax(self.layer_weights / self.temperature, dim=0)\n",
    "\n",
    "            # Calculate weighted loss\n",
    "            total_cosine_loss = sum(weight * loss for weight, loss in zip(normalized_weights, layer_losses))\n",
    "\n",
    "            # Combined loss using alpha parameter\n",
    "            distillation_loss = (1 - self.alpha) * weighted_detection_loss + self.alpha * total_cosine_loss\n",
    "            \n",
    "            # Calculate current component weights for logging\n",
    "            current_weights = precision.detach().cpu()\n",
    "            \n",
    "            # Safe scalar extraction for logging\n",
    "            orig_loss_val = original_loss.sum().item()\n",
    "            weighted_det_loss_val = weighted_detection_loss.item()\n",
    "            cosine_loss_val = total_cosine_loss.item()\n",
    "            dist_loss_val = distillation_loss.item()\n",
    "\n",
    "            # Store current weights for history\n",
    "            self.component_weight_history['box'].append(current_weights[0].item())\n",
    "            self.component_weight_history['cls'].append(current_weights[1].item())\n",
    "            self.component_weight_history['dfl'].append(current_weights[2].item())\n",
    "            \n",
    "            # Track metrics\n",
    "            self.detection_losses.append(weighted_det_loss_val)\n",
    "            self.cosine_losses.append(cosine_loss_val)\n",
    "            self.distillation_losses.append(dist_loss_val)\n",
    "\n",
    "            # Store weight values for monitoring\n",
    "            for i, layer_idx in enumerate(self.feature_layers):\n",
    "                self.layer_weight_values[layer_idx] = normalized_weights[i].item()\n",
    "\n",
    "            return distillation_loss, loss_items\n",
    " \n",
    "        # Set original criterion if not already done\n",
    "        if not hasattr(trainer.model, \"original_criterion\"):\n",
    "            trainer.model.original_criterion = trainer.model.init_criterion()\n",
    "            \n",
    "        trainer.model.criterion = distillation_criterion\n",
    "\n",
    "    def _add_optimizer_param_group(self, trainer, params, name, weight_decay_multiplier=1.0):\n",
    "\n",
    "        if not hasattr(trainer, 'optimizer') or trainer.optimizer is None:\n",
    "            return False\n",
    "            \n",
    "        # Check if this parameter group already exists\n",
    "        for group in trainer.optimizer.param_groups:\n",
    "            if group.get('name') == name:\n",
    "                LOGGER.info(f\"Parameter group '{name}' already exists, skipping addition\")\n",
    "                return False\n",
    "        \n",
    "        # Get base parameters from the first parameter group\n",
    "        pg0 = trainer.optimizer.param_groups[0]\n",
    "        \n",
    "        # Get all parameters from base group\n",
    "        param_values = {k: v for k, v in pg0.items() if k != 'params' and k != 'name'}\n",
    "\n",
    "        # Override weight decay with multiplier\n",
    "        if weight_decay_multiplier != 0:\n",
    "            param_values['weight_decay'] = param_values.get('weight_decay', 0.005) * weight_decay_multiplier\n",
    "        \n",
    "        # Create and add the parameter group\n",
    "        new_param_group = {\n",
    "            'params': params,\n",
    "            'name': name,\n",
    "            **param_values\n",
    "        }\n",
    "        \n",
    "        trainer.optimizer.add_param_group(new_param_group)\n",
    "\n",
    "        LOGGER.info(f\"Added parameter group '{name}' with {len(params) if isinstance(params, list) else sum(1 for _ in params.parameters())} parameters\")\n",
    "        return True\n",
    "    \n",
    "    def log_metrics(self, trainer):\n",
    "        \"\"\"Clean up hooks and log metrics at the end of each epoch\"\"\"\n",
    "        # Remove all hooks\n",
    "        for layer_idx, hook in self.teacher_hooks.items():\n",
    "            hook.remove()\n",
    "        for layer_idx, hook in self.student_hooks.items():\n",
    "            hook.remove()\n",
    "\n",
    "        if len(self.detection_losses) > 0:\n",
    "\n",
    "            # Log metrics\n",
    "            avg_detection = sum(self.detection_losses) / max(len(self.detection_losses), 1)\n",
    "            avg_cosine = sum(self.cosine_losses) / max(len(self.cosine_losses), 1)\n",
    "            avg_distillation = sum(self.distillation_losses) / max(len(self.distillation_losses), 1)\n",
    "            \n",
    "            # Log to wandb with per-layer metrics\n",
    "            try:\n",
    "                metrics_dict = {\n",
    "                    **trainer.metrics,\n",
    "                    \"metrics/fitness\": trainer.fitness, \n",
    "                    \"distillation/detection_loss\": avg_detection,\n",
    "                    \"distillation/cosine_loss\": avg_cosine, \n",
    "                    \"distillation/distillation_loss\": avg_distillation,\n",
    "                }\n",
    "                \n",
    "                # Add per-layer metrics if available\n",
    "                for layer_idx in self.feature_layers:\n",
    "                    layer_prefix = f\"distillation/layer_{layer_idx}\"\n",
    "\n",
    "                    adapter_key = f'adapter_{layer_idx}'\n",
    "                    if adapter_key in self.adapters:\n",
    "                        # Adapter network - transformation needed to make student features match teacher ones\n",
    "                        adapter_norm = torch.linalg.norm(next(self.adapters[adapter_key].parameters())).item()\n",
    "                        metrics_dict[f\"{layer_prefix}/adapter_norm\"] = adapter_norm\n",
    "                    #  Contribution weights\n",
    "                    metrics_dict[f\"{layer_prefix}/importance\"] = self.layer_weight_values[layer_idx]\n",
    "\n",
    "                    # Importance weights lr optimizer (only first layer)\n",
    "                    if hasattr(self, 'layer_weight_optimizer') and layer_idx == 0:\n",
    "                        # Only log once since it's shared across all layers\n",
    "                        for pg_idx, pg in enumerate(self.layer_weight_optimizer.param_groups):\n",
    "                            metrics_dict[f\"{layer_prefix}/importance_optimizer\"] = pg.get('lr', 0)\n",
    "\n",
    "                # Add component weights to metrics dictionary\n",
    "                if len(self.component_weight_history['box']) > 0:\n",
    "                    # Get the latest weight values\n",
    "                    metrics_dict[\"distillation/box_weight\"] = self.component_weight_history['box'][-1]\n",
    "                    metrics_dict[\"distillation/cls_weight\"] = self.component_weight_history['cls'][-1]\n",
    "                    metrics_dict[\"distillation/dfl_weight\"] = self.component_weight_history['dfl'][-1]\n",
    "\n",
    "                wandb.log(metrics_dict, commit=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                LOGGER.warning(f\"Failed to log metrics to wandb: {e}\")\n",
    "\n",
    "        # Clear metrics for next epoch\n",
    "        self.detection_losses = []\n",
    "        self.cosine_losses = []\n",
    "        self.distillation_losses = []\n",
    "        self.component_weight_history = {'box': [], 'cls': [], 'dfl': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Visualization Callback\n",
    "\n",
    "class FeatureVisualizationCallback:\n",
    "    \"\"\"\n",
    "    Callback for visualizing feature maps during distillation training.\n",
    "    \n",
    "    Periodically captures and visualizes feature activations from specified layers\n",
    "    of the student model to provide insights into the distillation process. The\n",
    "    visualizations are logged to Weights & Biases as images.\n",
    "    \n",
    "    The callback works by:\n",
    "    1. Registering hooks to capture feature maps at the start of specified epochs\n",
    "    2. Creating grid visualizations of feature channels\n",
    "    3. Logging these visualizations to W&B for monitoring and analysis\n",
    "    \n",
    "    Args:\n",
    "        layers (list): Layer indices to visualize features from (from config)\n",
    "        interval (int): Epoch interval between visualizations (from config)\n",
    "        figsize (tuple): Size of the generated matplotlib figures\n",
    "        grid_size (int): Number of feature channels per row/column in the grid\n",
    "    \n",
    "    Visualization only occurs every `interval` epochs to avoid excessive overhead\n",
    "    while still providing useful insights into the feature learning process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers, interval=20, figsize=(8.0, 8.0), grid_size=2):\n",
    "        self.layers = layers\n",
    "        self.interval = interval\n",
    "        self.features = {}\n",
    "        self.hooks = {}\n",
    "        self.figsize = figsize\n",
    "        self.grid_size = grid_size  # Number of images per row and column in each grid\n",
    "        \n",
    "    def set_hooks(self, trainer):\n",
    "        # Clear previous features and hooks\n",
    "        self.features = {}\n",
    "        \n",
    "        # Only register hooks on visualization epochs\n",
    "        if (trainer.epoch) % self.interval != 0:\n",
    "            return\n",
    "            \n",
    "        # Hook function to capture features\n",
    "        def get_features(layer_idx):\n",
    "            def hook(module, input, output):\n",
    "                # Store just one image from batch for visualization\n",
    "                self.features[layer_idx] = output[0].detach().clone()\n",
    "            return hook\n",
    "        \n",
    "        # Register hooks for both models\n",
    "        for layer_idx in self.layers:\n",
    "            self.hooks[layer_idx] = trainer.model.model[layer_idx].register_forward_hook(\n",
    "                get_features(layer_idx)\n",
    "            )\n",
    "    \n",
    "    def plot_figures(self, trainer):\n",
    "        # Skip if not visualization epoch\n",
    "        if (trainer.epoch) % self.interval != 0:\n",
    "            return\n",
    "            \n",
    "        # Remove hooks\n",
    "        for hook in self.hooks.values():\n",
    "            hook.remove()\n",
    "   \n",
    "        # Create visualizations for each layer\n",
    "        for layer_idx, feature_maps in self.features.items():\n",
    "            # Select all channels for visualization\n",
    "            num_channels = feature_maps.shape[0]\n",
    "            feature_subset = feature_maps.cpu()\n",
    "            \n",
    "            # Normalize each channel for better visualization\n",
    "            for i in range(feature_subset.size(0)):\n",
    "                min_val = feature_subset[i].min()\n",
    "                max_val = feature_subset[i].max()\n",
    "                if max_val > min_val:\n",
    "                    feature_subset[i] = (feature_subset[i] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            # Calculate how many grids we need to display all channels\n",
    "            channels_per_grid = self.grid_size * self.grid_size\n",
    "            num_grids = (num_channels + channels_per_grid - 1) // channels_per_grid  # Ceiling division\n",
    "            \n",
    "            # Create and log multiple grid images\n",
    "            for grid_idx in range(num_grids):\n",
    "                start_idx = grid_idx * channels_per_grid\n",
    "                end_idx = min(start_idx + channels_per_grid, num_channels)\n",
    "                current_channels = feature_subset[start_idx:end_idx]\n",
    "                \n",
    "                # Skip if no channels in this grid\n",
    "                if len(current_channels) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Create grid of feature maps\n",
    "                grid = vutils.make_grid(\n",
    "                    current_channels.unsqueeze(1),\n",
    "                    nrow=self.grid_size,\n",
    "                    padding=2\n",
    "                )\n",
    "                \n",
    "                # Convert grid to numpy for matplotlib\n",
    "                grid_np = grid.permute(1, 2, 0).numpy().astype(np.float32)\n",
    "                \n",
    "                # Create a matplotlib figure with specified size\n",
    "                plt.figure(figsize=self.figsize)\n",
    "                plt.imshow(grid_np)\n",
    "                plt.title(f\"Layer {layer_idx} Features - Epoch {trainer.epoch+1} - Group {grid_idx+1}/{num_grids}\")\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save figure to a buffer\n",
    "                buf = io.BytesIO()\n",
    "                plt.savefig(buf, format='png', dpi=100)\n",
    "                plt.close()\n",
    "                buf.seek(0)\n",
    "                \n",
    "                # Convert buffer to PIL Image\n",
    "                feature_image = Image.open(buf)\n",
    "                \n",
    "                # Log to wandb\n",
    "                wandb.log({f\"features/layer_{layer_idx}_epoch_{trainer.epoch+1}_group_{grid_idx+1}\": wandb.Image(feature_image)}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distillation Orchestrator\n",
    "\n",
    "class DistillationOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrates the knowledge distillation process between teacher and student YOLO models.\n",
    "    \n",
    "    This class handles the setup and coordination of all components needed for distillation:\n",
    "    - Initializes and connects teacher and student models\n",
    "    - Sets up feature extraction hooks at specified network layers\n",
    "    - Configures feature adaptation modules to match dimensions between models\n",
    "    - Registers callbacks for distillation loss calculation and visualization\n",
    "    - Manages learning rate scheduling (standard or cyclical)\n",
    "    \n",
    "    The orchestrator follows a callback-based architecture where different\n",
    "    components hook into the training process at specific points (epoch start/end,\n",
    "    training start, etc.) without modifying the core training loop.\n",
    "    \n",
    "    Most configuration parameters are passed through kwargs, which typically come from\n",
    "    a YAML config file (e.g., config[\"distillation\"] section). This allows for flexible\n",
    "    configuration without changing code.\n",
    "    \n",
    "    Key processes:\n",
    "    1. Pre-computing channel dimensions to create appropriate feature adapters\n",
    "    2. Setting up distillation callbacks to capture and compare features\n",
    "    3. Configuring learning rate schedulers (optional cyclical scheduler)\n",
    "    4. Managing feature visualization at specified intervals\n",
    "    \n",
    "    Args:\n",
    "        teacher_trainer (MergedClassDetectionTrainer): Trainer instance with teacher model\n",
    "        student_trainer (MergedClassDetectionTrainer): Trainer instance with student model\n",
    "        **kwargs: Configuration parameters typically from config[\"distillation\"], including:\n",
    "            feature_layers (list): Layer indices from which to extract features for distillation\n",
    "            temperature (float): Temperature parameter for softening importance weights\n",
    "            alpha (float): Weight balancing detection loss vs. distillation loss (0-1)\n",
    "            use_cyclical_lr (bool): Whether to use cyclical learning rate scheduling\n",
    "            max_lr (float): Maximum learning rate for cyclical scheduler\n",
    "            cycle_size (int): Number of epochs per learning rate cycle\n",
    "            group_scalers (dict): Per-parameter group learning rate multipliers\n",
    "            feature_plot_interval (int): Interval (in epochs) for feature map visualization\n",
    "    \n",
    "    Example:\n",
    "        ```\n",
    "        teacher_trainer = MergedClassDetectionTrainer(teacher_config)\n",
    "        student_trainer = MergedClassDetectionTrainer(student_config)\n",
    "        \n",
    "        # Load distillation settings from config\n",
    "        orchestrator = DistillationOrchestrator(\n",
    "            teacher_trainer=teacher_trainer,\n",
    "            student_trainer=student_trainer,\n",
    "            **config[\"distillation\"]\n",
    "        )\n",
    "        \n",
    "        # Start distillation training\n",
    "        results = orchestrator.start()\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            teacher_trainer : MergedClassDetectionTrainer, \n",
    "            student_trainer : MergedClassDetectionTrainer, \n",
    "            **kwargs\n",
    "        ):\n",
    "        \"\"\"Initialize with separate trainers for teacher and student\"\"\"\n",
    "        self.teacher_trainer = teacher_trainer\n",
    "        self.student_trainer = student_trainer\n",
    "        \n",
    "        self.feature_layers = kwargs.get(\"feature_layers\", [20])\n",
    "        self.temperature = kwargs.get(\"temperature\", 2.0)\n",
    "        self.alpha = kwargs.get(\"alpha\", 0.5)\n",
    "        self.use_cyclical_lr = kwargs.get(\"use_cyclical_lr\", False)\n",
    "        self.max_lr = kwargs.get(\"max_lr\", 0.01)\n",
    "        self.cycle_size = kwargs.get(\"cycle_size\", 20)\n",
    "        self.group_scalers = kwargs.get(\"group_scalers\", {0: 1.0, 1: 1.0, 2: 1.0})\n",
    "        self.visualize_feature_plot = kwargs.get(\"visualize_feature_plot\", False)\n",
    "        self.feature_plot_interval = kwargs.get(\"feature_plot_interval\", 20)\n",
    "        \n",
    "        # Access models for convenience\n",
    "        self.teacher_model = YOLO(self.teacher_trainer.args.model)\n",
    "        self.student_model = YOLO(self.student_trainer.args.model)\n",
    "\n",
    "        self.layer_channels = self._compute_all_channel_dimensions(self.feature_layers)\n",
    "        \n",
    "        if not self.feature_layers:\n",
    "            return\n",
    "            \n",
    "        # Create and register the distillation callback\n",
    "        self.distill_callback = DistillationCallback(\n",
    "            teacher_model=self.teacher_model,\n",
    "            temperature=self.temperature,\n",
    "            alpha=self.alpha,\n",
    "            feature_layers=self.feature_layers,\n",
    "            layer_channels=self.layer_channels\n",
    "        )\n",
    "        \n",
    "        # Add the callback to the student trainer\n",
    "        self.student_trainer.add_callback(\"on_train_start\", self.distill_callback.init_parameters)\n",
    "        self.student_trainer.add_callback(\"on_train_epoch_start\", self.distill_callback.setup_criterion)\n",
    "        self.student_trainer.add_callback(\"on_fit_epoch_end\", self.distill_callback.log_metrics)\n",
    "\n",
    "        # Visualization callback\n",
    "\n",
    "        if self.visualize_feature_plot:\n",
    "\n",
    "            visualization_callback = FeatureVisualizationCallback(layers=self.feature_layers, interval=self.feature_plot_interval)\n",
    "\n",
    "            self.student_trainer.add_callback(\"on_train_epoch_start\", visualization_callback.set_hooks)\n",
    "            self.student_trainer.add_callback(\"on_train_epoch_end\", visualization_callback.plot_figures)\n",
    "\n",
    "        if self.use_cyclical_lr:\n",
    "\n",
    "            cyclical_lr_scheduler_callback = DecayingCyclicalLRSchedulerCallback(\n",
    "                max_lr=self.max_lr,\n",
    "                cycle_size=self.cycle_size,\n",
    "                group_scalers=self.group_scalers\n",
    "            )\n",
    "            \n",
    "            student_trainer.add_callback(\"on_pretrain_routine_end\", cyclical_lr_scheduler_callback.set_scheduler)\n",
    "        else:\n",
    "            # Refresh default scheduler to ensure all parameter groups are included\n",
    "\n",
    "            def refresh_scheduler_callback(trainer):\n",
    "                \"\"\"\n",
    "                Refresh the scheduler once after all parameter groups have been added\n",
    "                to ensure proper learning rate scheduling for all groups.\n",
    "                \"\"\"\n",
    "                # Default YOLO scheduler with cosine lr - one_cycle\n",
    "                trainer.lf = one_cycle(1, trainer.args.lrf, trainer.epochs)  # cosine 1->hyp['lrf']\n",
    "                trainer.scheduler = optim.lr_scheduler.LambdaLR(trainer.optimizer, lr_lambda=trainer.lf)\n",
    "                \n",
    "                # Restore scheduler state\n",
    "                trainer.scheduler.last_epoch = trainer.start_epoch - 1\n",
    "                \n",
    "                LOGGER.info(f\"Refreshed scheduler to include all {len(trainer.optimizer.param_groups)} parameter groups\")\n",
    "            student_trainer.add_callback(\"on_train_start\", refresh_scheduler_callback)\n",
    "\n",
    "    def _compute_all_channel_dimensions(self, feature_layers):\n",
    "        \"\"\"Pre-compute channel dimensions for all feature layers\"\"\"\n",
    "        LOGGER.info(f\"Computing channel dimensions for {len(feature_layers)} layers...\")\n",
    "        \n",
    "        # Dictionary to store channel dimensions\n",
    "        layer_channels = {}\n",
    "        \n",
    "        # Function to extract channels from a single model\n",
    "        def get_model_channels(model, name):\n",
    "            device = next(model.parameters()).device\n",
    "            dtype = next(model.parameters()).dtype\n",
    "            \n",
    "            # Create a very small dummy input to minimize computation\n",
    "            dummy_input = torch.zeros(1, 3, self.student_trainer.args.imgsz, self.student_trainer.args.imgsz, device=device, dtype=dtype)\n",
    "            \n",
    "            # Store activation outputs\n",
    "            activations = {}\n",
    "            \n",
    "            # Define a clean hook function\n",
    "            def hook_func(idx):\n",
    "                def hook(module, input, output):\n",
    "                    activations[idx] = output\n",
    "                return hook\n",
    "            \n",
    "            # Register hooks\n",
    "            handles = []\n",
    "            for idx in feature_layers:\n",
    "                handles.append(model.model.model[idx].register_forward_hook(hook_func(idx)))\n",
    "            \n",
    "            # Do a single forward pass with no gradient computation\n",
    "            with torch.no_grad():\n",
    "                model.eval()  # Ensure model is in eval mode\n",
    "                _ = model(dummy_input)\n",
    "            \n",
    "            # Get channels and clean up\n",
    "            channels = {}\n",
    "            for idx, activation in activations.items():\n",
    "                channels[idx] = activation.shape[1]  # Channel dimension\n",
    "            \n",
    "            # Remove hooks\n",
    "            for handle in handles:\n",
    "                handle.remove()\n",
    "            \n",
    "            return channels\n",
    "        \n",
    "        # Get channels for both models\n",
    "        student_channels = get_model_channels(self.student_model, \"student\")\n",
    "        teacher_channels = get_model_channels(self.teacher_model, \"teacher\")\n",
    "        \n",
    "        # Combine and format results\n",
    "        for layer_idx in feature_layers:\n",
    "            s_ch = student_channels.get(layer_idx)\n",
    "            t_ch = teacher_channels.get(layer_idx)\n",
    "            \n",
    "            if s_ch is not None and t_ch is not None:\n",
    "                layer_channels[layer_idx] = {\n",
    "                    'student': s_ch,\n",
    "                    'teacher': t_ch\n",
    "                }\n",
    "                LOGGER.info(f\"Layer {layer_idx}: Student channels = {s_ch}, Teacher channels = {t_ch}\")\n",
    "            else:\n",
    "                LOGGER.warning(f\"Missing channel info for layer {layer_idx}\")\n",
    "        \n",
    "        return layer_channels\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Run distillation training by invoking student trainer once\"\"\"\n",
    "        LOGGER.info(f\"Distillation trainer initialized with temperature={self.temperature}, alpha={self.alpha}\")\n",
    "        results = self.student_trainer.train()\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb init\n",
    "\n",
    "settings.update({\n",
    "    \"wandb\": True\n",
    "})\n",
    "\n",
    "# TODO: A wandb warning for step sync sometimes pops up, most likely because of feature imgs logging. \n",
    "# All the wandb log should be aggregated in a single call at the end of fit/train epoch.\n",
    "\n",
    "key = get_wandb_key()\n",
    "wandb_run_id = shortuuid.uuid()[:8]\n",
    "wandb.login(key=key, relogin=True, force=True)\n",
    " \n",
    "run = wandb.init(\n",
    "    id=wandb_run_id,\n",
    "    save_code=True,\n",
    "    **config[\"wandb\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teacher model\n",
    "\n",
    "# Uncomment to use teacher model defined in config for distillation or use wandb artifact\n",
    "# teacher_model_path = config[\"distillation\"][\"teacher_model_path\"]\n",
    "\n",
    "# Wandb - Load teacher model artifact\n",
    "\n",
    "teacher_artifact = run.use_artifact(config[\"distillation\"][\"teacher_model_path\"], type='model')\n",
    "teacher_artifact_dir = teacher_artifact.download()\n",
    "teacher_model_path = f\"{teacher_artifact_dir}/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher trainer init\n",
    "\n",
    "teacher_config = config[\"train\"].copy()\n",
    "teacher_config.update({\n",
    "    \"model\": teacher_model_path,\n",
    "    \"freeze\": 21,\n",
    "})\n",
    "teacher_trainer = MergedClassDetectionTrainer(overrides=teacher_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config update\n",
    "\n",
    "config[\"distillation\"].update({\n",
    "    \"use_cyclical_lr\": True,\n",
    "    \"feature_layers\": [20],\n",
    "    \"visualize_feature_plot\": True,\n",
    "    \"temperature\": 4,\n",
    "    \"alpha\": 0.7,\n",
    "    \"max_lr\": 0.005,\n",
    "    \"cycle_size\": 3,   \n",
    "    \"group_scalers\": {0: 1.0, 1: 1.0, 2: 1.0}\n",
    "})\n",
    "\n",
    "# Trainer config\n",
    "\n",
    "config[\"train\"].update({\n",
    "    \"pretrained\": True,\n",
    "    \"epochs\": 1,\n",
    "    \"imgsz\": 640,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr0\": 0.005,\n",
    "    \"lrf\": 0.001,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"patience\": config[\"distillation\"][\"use_cyclical_lr\"] | 5,\n",
    "    \"batch\": 16,\n",
    "    \"workers\": 8,\n",
    "    \"momentum\": 0.937,\n",
    "    \"box\": 3.5,\n",
    "    \"cls\": 0.3,\n",
    "    \"dfl\": 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB log config\n",
    "\n",
    "wandb.log({\n",
    "    **config[\"train\"],\n",
    "    **config[\"val\"],\n",
    "    **config[\"distillation\"]\n",
    "}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student trainer init\n",
    "\n",
    "student_trainer = MergedClassDetectionTrainer(overrides=config[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestrator\n",
    "\n",
    "orchestrator = DistillationOrchestrator(\n",
    "    teacher_trainer=teacher_trainer,\n",
    "    student_trainer=student_trainer, \n",
    "    **config[\"distillation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run distillation training\n",
    "\n",
    "train_results = orchestrator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best student model artifact from wandb to test it\n",
    "\n",
    "student_model_path = os.path.join(orchestrator.student_trainer.args.save_dir, \"weights\", \"best.pt\")\n",
    "\n",
    "student_model_to_test = YOLO(student_model_path)\n",
    "\n",
    "test_results = student_model_to_test.val(\n",
    "    validator=MergedClassDetectionValidator, \n",
    "    **config['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixed_results_dict = {f\"test/{k}\": v for k, v in test_results.results_dict.items()}\n",
    "\n",
    "wandb.init(\n",
    "    id=run.id,\n",
    "    resume=\"must\",\n",
    ")\n",
    "\n",
    "# Prepare all metrics in their respective dictionaries\n",
    "metrics = {\n",
    "    \"test/metrics/fitness\": test_results.fitness,\n",
    "    **prefixed_results_dict\n",
    "}\n",
    "\n",
    "# Add speed metrics\n",
    "for key, value in test_results.speed.items():\n",
    "    metrics[f\"speed/{key}\"] = value\n",
    "\n",
    "# Add class-wise mAP values\n",
    "for i, map_value in enumerate(test_results.maps):\n",
    "    if i in test_results.names:\n",
    "        class_name = test_results.names[i]\n",
    "        metrics[f\"test/metrics/mAP/{class_name}\"] = float(map_value)\n",
    "\n",
    "# Log everything in a single call\n",
    "wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "remove_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
